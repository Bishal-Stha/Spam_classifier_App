{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98359448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Learning101\\ml_model_in_tensorflow\\tfjs-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54d1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data (Adjusted for spam.txt)\n",
    "# Most spam.txt files are Tab Separated. If yours uses commas, change sep='\\t' to sep=','\n",
    "df = pd.read_csv(\"spam.txt\", sep='\\t', names=[\"label\", \"message\"], encoding=\"latin-1\")\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"cleaned\"] = df[\"message\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab0e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "VOCAB_SIZE = 8000\n",
    "MAX_LEN = 100\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0af606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TOKENIZER for JS\n",
    "with open('tokenizer.json', 'w') as f:\n",
    "    json.dump(tokenizer.word_index, f)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(df[\"cleaned\"])\n",
    "X_pad = pad_sequences(X_seq, maxlen=MAX_LEN, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff04eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Learning101\\ml_model_in_tensorflow\\tfjs-env\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Learning101\\ml_model_in_tensorflow\\tfjs-env\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From d:\\Learning101\\ml_model_in_tensorflow\\tfjs-env\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Learning101\\ml_model_in_tensorflow\\tfjs-env\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "175/175 [==============================] - 4s 7ms/step - loss: 0.4805 - accuracy: 0.8580\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8659\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.2928 - accuracy: 0.8663\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.1781 - accuracy: 0.9282\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0951 - accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.0638 - accuracy: 0.9824\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.0490 - accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.0396 - accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9898\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0292 - accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1abc7d33ee0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Model\n",
    "model = Sequential([\n",
    "    Embedding(VOCAB_SIZE, 16, input_length=MAX_LEN), # Smaller embedding for light web use\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_pad, df[\"label\"], epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505f697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Tokenizer saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning101\\ml_model_in_tensorflow\\tfjs-env\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 4. Save Model\n",
    "model.save(\"spam_model.h5\")\n",
    "print(\"Model and Tokenizer saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfjs-env)",
   "language": "python",
   "name": "tfjs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
